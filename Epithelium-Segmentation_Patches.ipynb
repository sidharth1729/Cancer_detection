{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import os# data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "'''\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "'''\n",
    "#from tarfile import TarFile\n",
    "\n",
    "#TarFile.open(\"\",'r')\n",
    "\n",
    "#os.mkdir(\"/kaggle/working/image\")\n",
    "#os.mkdir(\"/kaggle/working/mask\")\n",
    "for i in [\"/kaggle/working/image\",\"/kaggle/working/mask\"]:\n",
    "    for j in os.listdir(i):\n",
    "        os.unlink(os.path.join(i,j))\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#from tarfile import TarFile\n",
    "#TarFile.open(\"/kaggle/input/epithelium-segmentation/nuclei.tgz\").extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as im\n",
    "import keras\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Activation,Input,BatchNormalization,Conv2DTranspose,concatenate\n",
    "from keras.models import Sequential\n",
    "from keras.utils import Sequence\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in os.listdir(\"/kaggle/working\"):\n",
    "    img = im.imread(os.path.join(\"/kaggle/working\",i))\n",
    "    plt.imshow(img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_shape=img.shape\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir(\"/kaggle/working/image\")\n",
    "#os.mkdir(\"/kaggle/working/mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to make image,mask directory\n",
    "\n",
    "image_path=[]\n",
    "mask_path=[]\n",
    "\n",
    "for i in os.listdir(\"/kaggle/working\"):\n",
    "    if \"_original\" in i:\n",
    "        image_path.append(i)\n",
    "    elif \"_mask\" in i:\n",
    "        mask_path.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 141\n"
     ]
    }
   ],
   "source": [
    "print(len(image_path),len(mask_path))\n",
    "\n",
    "total_number_of_images = len(image_path)\n",
    "path = \"/kaggle/working\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Generator(Sequence):\n",
    "    \n",
    "    def __init__(self,path,image_path,batch_size=32,total_number_of_images=141,number_of_channels=3,\n",
    "                  dim=(2000,2000),new_dim=(128,128)):\n",
    "        self.path=path\n",
    "        self.image_path=image_path\n",
    "        self.batch_size = batch_size\n",
    "        self.total_number_of_images=total_number_of_images\n",
    "        self.number_of_channels=number_of_channels\n",
    "        self.dim=dim\n",
    "        self.new_dim=new_dim\n",
    "        self.len = self.__len__()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (self.total_number_of_images//self.batch_size)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img1 = self.get_image(os.path.join(self.path,self.image_path[index]))\n",
    "        img2 = self.get_image(os.path.join(self.path,self.image_path[index]).replace(\"_original.tif\",\"_mask.png\"))\n",
    "        \n",
    "        self.patch_generator(img1,img2,self.image_path[index])\n",
    "        \n",
    "        \n",
    "    \n",
    "    def patch_generator(self,img1,img2,image_name):\n",
    "        \n",
    "        count  = 0 ;\n",
    "        for i in range(128,self.dim[0],128):\n",
    "            for j in range(128,self.dim[1],128):\n",
    "                count =count + 1\n",
    "                image = cv2.resize(img1[i-128:i,j-128:j],self.new_dim)\n",
    "                mask = cv2.resize(img2[i-128:i,j-128:j],self.new_dim)\n",
    "                cv2.imwrite(os.path.join(self.path+\"/image\",image_name).replace(\"_original.tif\",str(count)+\".png\"),image)\n",
    "                cv2.imwrite(os.path.join(self.path+\"/mask\",image_name).replace(\"_original.tif\",str(count)+\".png\"),mask)\n",
    "                \n",
    "                #print(os.path.join(self.path+\"/image\",image_name).replace(\"_original.tif\",str(count)+\".png\"))\n",
    "                #print(os.path.join(self.path+\"/mask\",image_name).replace(\"_original.tif\",str(count)+\".png\"))\n",
    "             \n",
    "                \n",
    "            \n",
    "    \n",
    "    def get_image(self,path):\n",
    "        img  = im.imread(path)\n",
    "        #img = img/255\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/image/14153_500_f00019_original1.png\n",
      "/kaggle/working/mask/14153_500_f00019_mask1.png\n"
     ]
    }
   ],
   "source": [
    "path = \"/kaggle/working\"\n",
    "image_name = image_path[0]\n",
    "count=1\n",
    "print(os.path.join(path+\"/image\",image_name).replace(\".tif\",str(count)+\".png\"))\n",
    "print(os.path.join(path+\"/mask\",image_name).replace(\"_original.tif\",\"_mask\"+str(count)+\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = Data_Generator(path,image_path)\n",
    "\n",
    "for i in range(total_number_of_images):\n",
    "    data_generator.__getitem__(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31725 31725\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(\"/kaggle/working/image\")),len(os.listdir(\"/kaggle/working/mask\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = os.listdir(\"/kaggle/working/image\")\n",
    "path = \"/kaggle/working\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Generator(Sequence):\n",
    "    \n",
    "    def __init__(self,path,image_paths,total_number_of_images,batch_size=32,number_of_channels=3,\n",
    "                  dim=(128,128),labels=[\"image\",\"maks\"]):\n",
    "        self.path=path\n",
    "        self.image_paths=image_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.total_number_of_images=total_number_of_images\n",
    "        self.number_of_channels=number_of_channels\n",
    "        self.dim=dim\n",
    "        #self.new_dim=new_dim\n",
    "        self.len = self.__len__()\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return (self.total_number_of_images//self.batch_size)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        #l1 = []\n",
    "        #l2=[]\n",
    "        img1 = self.get_image(os.path.join(self.path+\"/image\",self.image_paths[index]))\n",
    "        img2 = self.get_image(os.path.join(self.path+\"/mask\",self.image_paths[index]))\n",
    "        #l1.append(img1)\n",
    "        #l2.append(img2)\n",
    "        #self.patch_generator(img1,img2,self.image_path[index])\n",
    "        return (img1.reshape(1,*img1.shape),img2.reshape(1,*img2.shape,1))\n",
    "        #return (img1.reshape(1,*img1.shape),img2.reshape(*img2.shape,1))\n",
    "    \n",
    "        \n",
    "    def get_image(self,path):\n",
    "        img  = im.imread(path)\n",
    "        #img = img/255\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 31725\n",
    "train_image = image_paths[:23793]\n",
    "validation_image = image_paths[23793:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23793 7932\n"
     ]
    }
   ],
   "source": [
    "print(len(train_image),len(validation_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  Data_Generator(path,train_image,len(train_image))\n",
    "validation_data = Data_Generator(path,validation_image,len(validation_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743 247\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_623 (Conv2D)             (None, 128, 128, 16) 448         input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 128, 128, 16) 64          conv2d_623[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 128, 128, 16) 0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_125 (MaxPooling2D (None, 64, 64, 16)   0           activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)           (None, 64, 64, 16)   0           max_pooling2d_125[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_625 (Conv2D)             (None, 64, 64, 32)   4640        dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 64, 64, 32)   128         conv2d_625[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 64, 64, 32)   0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_126 (MaxPooling2D (None, 32, 32, 32)   0           activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_172 (Dropout)           (None, 32, 32, 32)   0           max_pooling2d_126[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_627 (Conv2D)             (None, 32, 32, 64)   18496       dropout_172[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 32, 32, 64)   256         conv2d_627[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 32, 32, 64)   0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_127 (MaxPooling2D (None, 16, 16, 64)   0           activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)           (None, 16, 16, 64)   0           max_pooling2d_127[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_629 (Conv2D)             (None, 16, 16, 128)  73856       dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 16, 16, 128)  512         conv2d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 16, 16, 128)  0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_128 (MaxPooling2D (None, 8, 8, 128)    0           activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)           (None, 8, 8, 128)    0           max_pooling2d_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)             (None, 8, 8, 256)    295168      dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 8, 8, 256)    1024        conv2d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 8, 8, 256)    0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_70 (Conv2DTran (None, 16, 16, 128)  295040      activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 16, 16, 256)  0           conv2d_transpose_70[0][0]        \n",
      "                                                                 activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_175 (Dropout)           (None, 16, 16, 256)  0           concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)             (None, 16, 16, 128)  295040      dropout_175[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 16, 16, 128)  512         conv2d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 16, 16, 128)  0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_71 (Conv2DTran (None, 32, 32, 64)   73792       activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 32, 32, 128)  0           conv2d_transpose_71[0][0]        \n",
      "                                                                 activation_342[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)           (None, 32, 32, 128)  0           concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_635 (Conv2D)             (None, 32, 32, 64)   73792       dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 32, 32, 64)   256         conv2d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 32, 32, 64)   0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_72 (Conv2DTran (None, 64, 64, 32)   18464       activation_350[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 64, 64, 64)   0           conv2d_transpose_72[0][0]        \n",
      "                                                                 activation_340[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_177 (Dropout)           (None, 64, 64, 64)   0           concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_637 (Conv2D)             (None, 64, 64, 32)   18464       dropout_177[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_352 (BatchN (None, 64, 64, 32)   128         conv2d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_352 (Activation)     (None, 64, 64, 32)   0           batch_normalization_352[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_73 (Conv2DTran (None, 128, 128, 16) 4624        activation_352[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 128, 128, 32) 0           conv2d_transpose_73[0][0]        \n",
      "                                                                 activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_178 (Dropout)           (None, 128, 128, 32) 0           concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_639 (Conv2D)             (None, 128, 128, 16) 4624        dropout_178[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_354 (BatchN (None, 128, 128, 16) 64          conv2d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_354 (Activation)     (None, 128, 128, 16) 0           batch_normalization_354[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_640 (Conv2D)             (None, 128, 128, 1)  17          activation_354[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,179,409\n",
      "Trainable params: 1,177,937\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
    "    # Contracting Path\n",
    "    #model = Sequence()\n",
    "    #model.add()\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    #print(outputs)\n",
    "    return model\n",
    "\n",
    "model = get_unet(Input((128,128, 3)))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import numpy as np \\nimport os\\nimport skimage.io as io\\nimport skimage.transform as trans\\nimport numpy as np\\nfrom keras.models import *\\nfrom keras.layers import *\\nfrom keras.optimizers import *\\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler,EarlyStopping\\nfrom keras import backend as tensorflow\\n\\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler,EarlyStopping\\n\\n\\ndef unet(pretrained_weights = None,input_size = (128,128,3)):\\n    inputs = Input(input_size)\\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\\n    drop4 = Dropout(0.5)(conv4)\\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\\n\\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\\n    drop5 = Dropout(0.5)(conv5)\\n\\n    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\\n    merge6 = concatenate([drop4,up6], axis = 3)\\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\\n\\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\\n    merge7 = concatenate([conv3,up7], axis = 3)\\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\\n\\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\\n    merge8 = concatenate([conv2,up8], axis = 3)\\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\\n\\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\\n    merge9 = concatenate([conv1,up9], axis = 3)\\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\\n    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\\n    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\\n\\n    model = Model(input = inputs, output = conv10)\\n    return model\\n\\nmodel = unet()\\n\""
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler,EarlyStopping\n",
    "from keras import backend as tensorflow\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler,EarlyStopping\n",
    "\n",
    "\n",
    "def unet(pretrained_weights = None,input_size = (128,128,3)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "    return model\n",
    "\n",
    "model = unet()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "743/743 [==============================] - 87s 118ms/step - loss: 0.0836 - accuracy: 0.9746 - val_loss: 0.0079 - val_accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "mod=model.fit_generator(generator=train_data,epochs=20,validation_data=validation_data,shuffle=True,callbacks=[EarlyStopping(monitor='val_loss',patience=3)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
