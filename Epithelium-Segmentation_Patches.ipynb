{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd\nimport os# data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n'''\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n#from tarfile import TarFile\n\n#TarFile.open(\"\",'r')\n\n#os.mkdir(\"/kaggle/working/image\")\n#os.mkdir(\"/kaggle/working/mask\")\nfor i in [\"/kaggle/working/image\",\"/kaggle/working/mask\"]:\n    for j in os.listdir(i):\n        os.unlink(os.path.join(i,j))\n# Any results you write to the current directory are saved as output.","execution_count":498,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#from tarfile import TarFile\n#TarFile.open(\"/kaggle/input/epithelium-segmentation/nuclei.tgz\").extractall()","execution_count":499,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as im\nimport keras\nfrom keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Activation,Input,BatchNormalization,Conv2DTranspose,concatenate\nfrom keras.models import Sequential\nfrom keras.utils import Sequence\nfrom PIL import Image\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model","execution_count":500,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in os.listdir(\"/kaggle/working\"):\n    img = im.imread(os.path.join(\"/kaggle/working\",i))\n    plt.imshow(img)\n    break","execution_count":501,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_shape=img.shape\nimage_shape","execution_count":502,"outputs":[{"output_type":"execute_result","execution_count":502,"data":{"text/plain":"(2000, 2000)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#os.mkdir(\"/kaggle/working/image\")\n#os.mkdir(\"/kaggle/working/mask\")","execution_count":503,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#uncomment to make image,mask directory\n\nimage_path=[]\nmask_path=[]\n\nfor i in os.listdir(\"/kaggle/working\"):\n    if \"_original\" in i:\n        image_path.append(i)\n    elif \"_mask\" in i:\n        mask_path.append(i)\n        ","execution_count":504,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(image_path),len(mask_path))\n\ntotal_number_of_images = len(image_path)\npath = \"/kaggle/working\"","execution_count":505,"outputs":[{"output_type":"stream","text":"141 141\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Data_Generator(Sequence):\n    \n    def __init__(self,path,image_path,batch_size=32,total_number_of_images=141,number_of_channels=3,\n                  dim=(2000,2000),new_dim=(128,128)):\n        self.path=path\n        self.image_path=image_path\n        self.batch_size = batch_size\n        self.total_number_of_images=total_number_of_images\n        self.number_of_channels=number_of_channels\n        self.dim=dim\n        self.new_dim=new_dim\n        self.len = self.__len__()\n    \n    def __len__(self):\n        return (self.total_number_of_images//self.batch_size)\n    \n    def __getitem__(self,index):\n        img1 = self.get_image(os.path.join(self.path,self.image_path[index]))\n        img2 = self.get_image(os.path.join(self.path,self.image_path[index]).replace(\"_original.tif\",\"_mask.png\"))\n        \n        self.patch_generator(img1,img2,self.image_path[index])\n        \n        \n    \n    def patch_generator(self,img1,img2,image_name):\n        \n        count  = 0 ;\n        for i in range(128,self.dim[0],128):\n            for j in range(128,self.dim[1],128):\n                count =count + 1\n                image = cv2.resize(img1[i-128:i,j-128:j],self.new_dim)\n                mask = cv2.resize(img2[i-128:i,j-128:j],self.new_dim)\n                cv2.imwrite(os.path.join(self.path+\"/image\",image_name).replace(\"_original.tif\",str(count)+\".png\"),image)\n                cv2.imwrite(os.path.join(self.path+\"/mask\",image_name).replace(\"_original.tif\",str(count)+\".png\"),mask)\n                \n                #print(os.path.join(self.path+\"/image\",image_name).replace(\"_original.tif\",str(count)+\".png\"))\n                #print(os.path.join(self.path+\"/mask\",image_name).replace(\"_original.tif\",str(count)+\".png\"))\n             \n                \n            \n    \n    def get_image(self,path):\n        img  = im.imread(path)\n        #img = img/255\n        \n        return img","execution_count":506,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"/kaggle/working\"\nimage_name = image_path[0]\ncount=1\nprint(os.path.join(path+\"/image\",image_name).replace(\".tif\",str(count)+\".png\"))\nprint(os.path.join(path+\"/mask\",image_name).replace(\"_original.tif\",\"_mask\"+str(count)+\".png\"))","execution_count":507,"outputs":[{"output_type":"stream","text":"/kaggle/working/image/14153_500_f00019_original1.png\n/kaggle/working/mask/14153_500_f00019_mask1.png\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_generator = Data_Generator(path,image_path)\n\nfor i in range(total_number_of_images):\n    data_generator.__getitem__(i)\n    ","execution_count":508,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(os.listdir(\"/kaggle/working/image\")),len(os.listdir(\"/kaggle/working/mask\")))","execution_count":509,"outputs":[{"output_type":"stream","text":"31725 31725\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_paths = os.listdir(\"/kaggle/working/image\")\npath = \"/kaggle/working\"","execution_count":510,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Data_Generator(Sequence):\n    \n    def __init__(self,path,image_paths,total_number_of_images,batch_size=32,number_of_channels=3,\n                  dim=(128,128),labels=[\"image\",\"maks\"]):\n        self.path=path\n        self.image_paths=image_paths\n        self.batch_size = batch_size\n        self.total_number_of_images=total_number_of_images\n        self.number_of_channels=number_of_channels\n        self.dim=dim\n        #self.new_dim=new_dim\n        self.len = self.__len__()\n        \n    \n    def __len__(self):\n        return (self.total_number_of_images//self.batch_size)\n    \n    def __getitem__(self,index):\n        #l1 = []\n        #l2=[]\n        img1 = self.get_image(os.path.join(self.path+\"/image\",self.image_paths[index]))\n        img2 = self.get_image(os.path.join(self.path+\"/mask\",self.image_paths[index]))\n        #l1.append(img1)\n        #l2.append(img2)\n        #self.patch_generator(img1,img2,self.image_path[index])\n        return (img1.reshape(1,*img1.shape),img2.reshape(1,*img2.shape,1))\n        #return (img1.reshape(1,*img1.shape),img2.reshape(*img2.shape,1))\n    \n        \n    def get_image(self,path):\n        img  = im.imread(path)\n        #img = img/255\n        \n        return img","execution_count":511,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = 31725\ntrain_image = image_paths[:23793]\nvalidation_image = image_paths[23793:]","execution_count":512,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_image),len(validation_image))","execution_count":513,"outputs":[{"output_type":"stream","text":"23793 7932\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data =  Data_Generator(path,train_image,len(train_image))\nvalidation_data = Data_Generator(path,validation_image,len(validation_image))","execution_count":514,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_data),len(validation_data))","execution_count":515,"outputs":[{"output_type":"stream","text":"743 247\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n    # first layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\n              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    # second layer\n    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\n              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    return x\n\ndef get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n    # Contracting Path\n    #model = Sequence()\n    #model.add()\n    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n    p1 = MaxPooling2D((2, 2))(c1)\n    p1 = Dropout(dropout)(p1)\n    \n    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n    p2 = MaxPooling2D((2, 2))(c2)\n    p2 = Dropout(dropout)(p2)\n    \n    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n    p3 = MaxPooling2D((2, 2))(c3)\n    p3 = Dropout(dropout)(p3)\n    \n    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    p4 = MaxPooling2D((2, 2))(c4)\n    p4 = Dropout(dropout)(p4)\n    \n    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n    \n    # Expansive Path\n    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n    u6 = concatenate([u6, c4])\n    u6 = Dropout(dropout)(u6)\n    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n    \n    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n    u7 = concatenate([u7, c3])\n    u7 = Dropout(dropout)(u7)\n    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n    \n    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n    u8 = concatenate([u8, c2])\n    u8 = Dropout(dropout)(u8)\n    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n    \n    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n    u9 = concatenate([u9, c1])\n    u9 = Dropout(dropout)(u9)\n    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n    \n    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n    model = Model(inputs=[input_img], outputs=[outputs])\n    #print(outputs)\n    return model\n\nmodel = get_unet(Input((128,128, 3)))\nmodel.summary()\n","execution_count":516,"outputs":[{"output_type":"stream","text":"Model: \"model_29\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_27 (InputLayer)           (None, 128, 128, 3)  0                                            \n__________________________________________________________________________________________________\nconv2d_642 (Conv2D)             (None, 128, 128, 16) 448         input_27[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_356 (BatchN (None, 128, 128, 16) 64          conv2d_642[0][0]                 \n__________________________________________________________________________________________________\nactivation_356 (Activation)     (None, 128, 128, 16) 0           batch_normalization_356[0][0]    \n__________________________________________________________________________________________________\nmax_pooling2d_129 (MaxPooling2D (None, 64, 64, 16)   0           activation_356[0][0]             \n__________________________________________________________________________________________________\ndropout_179 (Dropout)           (None, 64, 64, 16)   0           max_pooling2d_129[0][0]          \n__________________________________________________________________________________________________\nconv2d_644 (Conv2D)             (None, 64, 64, 32)   4640        dropout_179[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_358 (BatchN (None, 64, 64, 32)   128         conv2d_644[0][0]                 \n__________________________________________________________________________________________________\nactivation_358 (Activation)     (None, 64, 64, 32)   0           batch_normalization_358[0][0]    \n__________________________________________________________________________________________________\nmax_pooling2d_130 (MaxPooling2D (None, 32, 32, 32)   0           activation_358[0][0]             \n__________________________________________________________________________________________________\ndropout_180 (Dropout)           (None, 32, 32, 32)   0           max_pooling2d_130[0][0]          \n__________________________________________________________________________________________________\nconv2d_646 (Conv2D)             (None, 32, 32, 64)   18496       dropout_180[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_360 (BatchN (None, 32, 32, 64)   256         conv2d_646[0][0]                 \n__________________________________________________________________________________________________\nactivation_360 (Activation)     (None, 32, 32, 64)   0           batch_normalization_360[0][0]    \n__________________________________________________________________________________________________\nmax_pooling2d_131 (MaxPooling2D (None, 16, 16, 64)   0           activation_360[0][0]             \n__________________________________________________________________________________________________\ndropout_181 (Dropout)           (None, 16, 16, 64)   0           max_pooling2d_131[0][0]          \n__________________________________________________________________________________________________\nconv2d_648 (Conv2D)             (None, 16, 16, 128)  73856       dropout_181[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_362 (BatchN (None, 16, 16, 128)  512         conv2d_648[0][0]                 \n__________________________________________________________________________________________________\nactivation_362 (Activation)     (None, 16, 16, 128)  0           batch_normalization_362[0][0]    \n__________________________________________________________________________________________________\nmax_pooling2d_132 (MaxPooling2D (None, 8, 8, 128)    0           activation_362[0][0]             \n__________________________________________________________________________________________________\ndropout_182 (Dropout)           (None, 8, 8, 128)    0           max_pooling2d_132[0][0]          \n__________________________________________________________________________________________________\nconv2d_650 (Conv2D)             (None, 8, 8, 256)    295168      dropout_182[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_364 (BatchN (None, 8, 8, 256)    1024        conv2d_650[0][0]                 \n__________________________________________________________________________________________________\nactivation_364 (Activation)     (None, 8, 8, 256)    0           batch_normalization_364[0][0]    \n__________________________________________________________________________________________________\nconv2d_transpose_74 (Conv2DTran (None, 16, 16, 128)  295040      activation_364[0][0]             \n__________________________________________________________________________________________________\nconcatenate_117 (Concatenate)   (None, 16, 16, 256)  0           conv2d_transpose_74[0][0]        \n                                                                 activation_362[0][0]             \n__________________________________________________________________________________________________\ndropout_183 (Dropout)           (None, 16, 16, 256)  0           concatenate_117[0][0]            \n__________________________________________________________________________________________________\nconv2d_652 (Conv2D)             (None, 16, 16, 128)  295040      dropout_183[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_366 (BatchN (None, 16, 16, 128)  512         conv2d_652[0][0]                 \n__________________________________________________________________________________________________\nactivation_366 (Activation)     (None, 16, 16, 128)  0           batch_normalization_366[0][0]    \n__________________________________________________________________________________________________\nconv2d_transpose_75 (Conv2DTran (None, 32, 32, 64)   73792       activation_366[0][0]             \n__________________________________________________________________________________________________\nconcatenate_118 (Concatenate)   (None, 32, 32, 128)  0           conv2d_transpose_75[0][0]        \n                                                                 activation_360[0][0]             \n__________________________________________________________________________________________________\ndropout_184 (Dropout)           (None, 32, 32, 128)  0           concatenate_118[0][0]            \n__________________________________________________________________________________________________\nconv2d_654 (Conv2D)             (None, 32, 32, 64)   73792       dropout_184[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_368 (BatchN (None, 32, 32, 64)   256         conv2d_654[0][0]                 \n__________________________________________________________________________________________________\nactivation_368 (Activation)     (None, 32, 32, 64)   0           batch_normalization_368[0][0]    \n__________________________________________________________________________________________________\nconv2d_transpose_76 (Conv2DTran (None, 64, 64, 32)   18464       activation_368[0][0]             \n__________________________________________________________________________________________________\nconcatenate_119 (Concatenate)   (None, 64, 64, 64)   0           conv2d_transpose_76[0][0]        \n                                                                 activation_358[0][0]             \n__________________________________________________________________________________________________\ndropout_185 (Dropout)           (None, 64, 64, 64)   0           concatenate_119[0][0]            \n__________________________________________________________________________________________________\nconv2d_656 (Conv2D)             (None, 64, 64, 32)   18464       dropout_185[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_370 (BatchN (None, 64, 64, 32)   128         conv2d_656[0][0]                 \n__________________________________________________________________________________________________\nactivation_370 (Activation)     (None, 64, 64, 32)   0           batch_normalization_370[0][0]    \n__________________________________________________________________________________________________\nconv2d_transpose_77 (Conv2DTran (None, 128, 128, 16) 4624        activation_370[0][0]             \n__________________________________________________________________________________________________\nconcatenate_120 (Concatenate)   (None, 128, 128, 32) 0           conv2d_transpose_77[0][0]        \n                                                                 activation_356[0][0]             \n__________________________________________________________________________________________________\ndropout_186 (Dropout)           (None, 128, 128, 32) 0           concatenate_120[0][0]            \n__________________________________________________________________________________________________\nconv2d_658 (Conv2D)             (None, 128, 128, 16) 4624        dropout_186[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_372 (BatchN (None, 128, 128, 16) 64          conv2d_658[0][0]                 \n__________________________________________________________________________________________________\nactivation_372 (Activation)     (None, 128, 128, 16) 0           batch_normalization_372[0][0]    \n__________________________________________________________________________________________________\nconv2d_659 (Conv2D)             (None, 128, 128, 1)  17          activation_372[0][0]             \n==================================================================================================\nTotal params: 1,179,409\nTrainable params: 1,177,937\nNon-trainable params: 1,472\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''import numpy as np \nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport numpy as np\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler,EarlyStopping\nfrom keras import backend as tensorflow\n\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler,EarlyStopping\n\n\ndef unet(pretrained_weights = None,input_size = (128,128,3)):\n    inputs = Input(input_size)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = concatenate([drop4,up6], axis = 3)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n\n    model = Model(input = inputs, output = conv10)\n    return model\n\nmodel = unet()\n'''","execution_count":517,"outputs":[{"output_type":"execute_result","execution_count":517,"data":{"text/plain":"\"import numpy as np \\nimport os\\nimport skimage.io as io\\nimport skimage.transform as trans\\nimport numpy as np\\nfrom keras.models import *\\nfrom keras.layers import *\\nfrom keras.optimizers import *\\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler,EarlyStopping\\nfrom keras import backend as tensorflow\\n\\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler,EarlyStopping\\n\\n\\ndef unet(pretrained_weights = None,input_size = (128,128,3)):\\n    inputs = Input(input_size)\\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\\n    drop4 = Dropout(0.5)(conv4)\\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\\n\\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\\n    drop5 = Dropout(0.5)(conv5)\\n\\n    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\\n    merge6 = concatenate([drop4,up6], axis = 3)\\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\\n\\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\\n    merge7 = concatenate([conv3,up7], axis = 3)\\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\\n\\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\\n    merge8 = concatenate([conv2,up8], axis = 3)\\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\\n\\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\\n    merge9 = concatenate([conv1,up9], axis = 3)\\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\\n    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\\n    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\\n\\n    model = Model(input = inputs, output = conv10)\\n    return model\\n\\nmodel = unet()\\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',metrics=['accuracy'],optimizer='adam')","execution_count":518,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod=model.fit_generator(generator=train_data,epochs=20,validation_data=validation_data,shuffle=True,callbacks=[EarlyStopping(monitor='val_loss',patience=3)])","execution_count":519,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n743/743 [==============================] - 86s 116ms/step - loss: 0.0834 - accuracy: 0.9732 - val_loss: 0.0097 - val_accuracy: 0.9763\nEpoch 2/20\n743/743 [==============================] - 82s 110ms/step - loss: 0.0057 - accuracy: 0.9769 - val_loss: 0.0025 - val_accuracy: 0.9763\nEpoch 3/20\n743/743 [==============================] - 83s 112ms/step - loss: 0.0022 - accuracy: 0.9769 - val_loss: 0.0011 - val_accuracy: 0.9763\nEpoch 4/20\n743/743 [==============================] - 82s 111ms/step - loss: 0.0014 - accuracy: 0.9769 - val_loss: 5.3063e-04 - val_accuracy: 0.9763\nEpoch 5/20\n743/743 [==============================] - 84s 113ms/step - loss: 0.0011 - accuracy: 0.9769 - val_loss: 3.9220e-04 - val_accuracy: 0.9763\nEpoch 6/20\n743/743 [==============================] - 82s 111ms/step - loss: 9.9274e-04 - accuracy: 0.9769 - val_loss: 2.8691e-04 - val_accuracy: 0.9763\nEpoch 7/20\n743/743 [==============================] - 83s 111ms/step - loss: 9.3236e-04 - accuracy: 0.9769 - val_loss: 2.4977e-04 - val_accuracy: 0.9763\nEpoch 8/20\n743/743 [==============================] - 81s 109ms/step - loss: 8.9382e-04 - accuracy: 0.9769 - val_loss: 2.0842e-04 - val_accuracy: 0.9763\nEpoch 9/20\n743/743 [==============================] - 82s 110ms/step - loss: 8.7501e-04 - accuracy: 0.9769 - val_loss: 2.0069e-04 - val_accuracy: 0.9763\nEpoch 10/20\n743/743 [==============================] - 81s 109ms/step - loss: 8.6161e-04 - accuracy: 0.9769 - val_loss: 2.1098e-04 - val_accuracy: 0.9763\nEpoch 11/20\n743/743 [==============================] - 84s 113ms/step - loss: 8.5227e-04 - accuracy: 0.9769 - val_loss: 1.8343e-04 - val_accuracy: 0.9763\nEpoch 12/20\n743/743 [==============================] - 86s 116ms/step - loss: 8.4321e-04 - accuracy: 0.9769 - val_loss: 1.1588e-04 - val_accuracy: 0.9763\nEpoch 13/20\n743/743 [==============================] - 84s 113ms/step - loss: 8.3034e-04 - accuracy: 0.9769 - val_loss: 1.3379e-04 - val_accuracy: 0.9763\nEpoch 14/20\n743/743 [==============================] - 84s 114ms/step - loss: 8.2639e-04 - accuracy: 0.9769 - val_loss: 1.9575e-04 - val_accuracy: 0.9763\nEpoch 15/20\n743/743 [==============================] - 83s 112ms/step - loss: 8.2491e-04 - accuracy: 0.9769 - val_loss: 1.5915e-04 - val_accuracy: 0.9763\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nf,ax = plt.subplots(1,10)\n#print(ax)\npath=\"/kaggle/working/\"\n\nl = os.listdir(\"/kaggle/working/image\")\n\nfor i in range(10):\n    ax[i].imshow(im.imread(path+\"mask/\"+l[i+2000]))\n    #ax[i].imshow(path+\"mask/\"+l[i])\nplt.show()\n'''","execution_count":539,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 10 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAA/CAYAAADuQgP7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAACapJREFUeJztnV+MVNUdxz8/dtl/VJA/i+z6B6RBLFQCSCuowSYkLpJa+1ANmPgvNDRGHvrQRGjT+GaqfWlNG1sfSLVJrdoXIRWI0sSaWqxQUdQILgqCO7uwihTZZdldfn2Yu8vs7szszuy9c+/Mfj/Jzdx79txzPjk7+d1zzz13jrk7QgghKpdJcQsIIYSIFgV6IYSocBTohRCiwlGgF0KICkeBXgghKhwFeiGEqHAiCfRmttbMDplZq5ltiaKOcvJIkos85CGP8vMYN+4e6gZUAUeA+UAN8C6wKOx6ysUjSS7ykIc8ys8jjC2KHv13gVZ3/8TdLwB/Be6KoJ5y8UiSizzkIY/y8xg3Fly5wivQ7EfAWnf/cXB8H3CTu2/OdU6N1XodU0L16OUC/fQyUG4vPfTTTx0NnOccF7zHSuGRzwU8ER51NHCW053u3igPecijOI8oXXKRK5YNpzqCurNVOuJqYmabgE0AdTRwk60JVaLDT/AF7SyyFQCk/Bhn+JLrbRlv+Z6SeeRzOcOXifC43pbxmv/tmDzkIY/CPErlkovMWJaPKIZuTgBXZxxfBbQNz+Tuz7j7CndfMZna0CVqqec83YPH5+mmlvoR+aL2GKuLPCamx+62Azy94ziLb+tgd9uB2DxgZHvcu/UID289PegVl0dS2iPOGDJeogj0bwMLzOxaM6sB1gPbI6gnL1OZTjdf0+3nuOgX6eA4jTSVWiNRLvJIlsdAAP3O0jpaP+3l08962XH0nUS0x46j7/DCy19zZ0vphiGyeUzk70eYhD504+59ZrYZ2E36qfU2d/8g7HpGY5JNYqEv5R3ewHGamcc3bFqpNfK7lPiHQ5PSJvIYSnW18dTjjdyxoY3+fufRR6fy+pPxtcfJ+a+xeLXz0PqpLF5Y+h5qUv4vSfEIgyjG6HH3V4BXoii7EGZZE7MScgVOios8kuGRORwCsG7NFNatudR7fv3JUhulmWVN7P/X3HgqH+aRhO/H/lQHMCc46qGlOU6b4tGbsULEQEvz0rgVxCgMvxjnSisHFOiFEIOUayALm3ztUI5tpEAvREyoVy9KhQK9EDGiYC9KQSIC/XVLutjddmBwE0LEgy48aSqtHRIR6IWYyAwPKpUWZET8RDK9cjzoSy4mIkn63rc0Lx28s77k1RqfUExktkO5ox69EGIELc1LE3XxiYtKaYPE9eiFECJJZA/25XWHk4hAf/i9hiGNOfK2UQghRLEkbugmc0ysUsbHhBAiThLRo8/H7rYD6tkLIUpGrg5mOcehxPXoy7kxhRDlzWg/fVCuowyj9ujNbBvwfeCku387SJsBvADMA44C97j7aTMz4LfAOqALeNDd/1uoVLbpXR/4PjpJUUMtq+x2AHr9AgfZSzdd1NPADaxkstXg7hzmXTpJUUU1i1jBVJteqEZW5JFcF3nIYzweN6/u5/RXc5h+eRXuzk9/2cnOPV001BvbfjOb5UvqgHTAr4r/hzULYiw9+j8Ba4elbQH2uPsCYE9wDHAHsCDYNgFPFys2fHpXM3NZxq1D8hzlI2Ywm1tsLTOYzVE+AuAL2uniLDezlm+xnI8o+FqTE3kk10Ue8ijW4+vUHNbc2sATvzsNwM5/dPHxJ70cevMa/vDr2Tyy5VRoHnEwaqB3939CxuKmae4Cng32nwV+mJH+nKfZC1xuZqFc+6ZbI5OpGZJ2ijaaSP92dhNzORWsWDiQbmZMs5n00UuPd48oUx7hkBQXechjPB7333MZL+86B8D2Xee47+7LMDNW3ljHV/+7SKqjLxSPOCj2YewV7p4CcPeUmc0O0q8EjmfkOxGkpYpXzM0Feqi19BqOtVbPBe8BoIdu6mgYzFdLPT051nuURzQkxUUeE88j3zj66qYFOT2arqjmZGc/AJ+393F186XweFVTNZ+n+mi6IvHzV7IS9sNYy5KWdcE8M9tkZvvMbF8vPQVVMtpDkewr9GVTG5/HaMijeBd5yKMYj9Eelj73nw/H5pFFxAKN4RNGom6TMCg20HcMDMkEnyeD9BPA1Rn5roLgnmwYYaycPv+bDN7W9Xg3NUE5ddRznq7BfOkeQV3WMsLwqKFWHiG7yEMehXqMdUbMvIXns3qkOvqYPasKSPfgj7ddGqo5keqjeU511lmBYbVJlBQb6LcDDwT7DwAvZ6Tfb2lWAmcGhnii4M7bp3DHz/cCkOIYjaQXdGykmRTHcHfO+BdUM3nw9iwKBuqTR/Jc5CGPsXi0NC/luRfP8oOW9Lq9d7ZM4c8vncXd2bv/PNMum8SDy1ZE5hE1Y5le+TzwPWCWmZ0AHgN+BbxoZhuBz4C7g+yvkJ5a2Up6euVDYYke9Lc4zSl66eGa5ed47GczeXTzdNb/pJ1/+y7qqGcJqwCYyRw6aedNdjGJKhYT3j8o0+MN/zvzWcRcFnKQvXzuRyecR5Jc5CGPfNz7cDuvv9lNx8mLtDLSY//j9Rz+cCoA69Y0sHNPF9etOkbHsQYWc0uu0c6yYNRA7+4bcvxpTZa8DjwyXqls3GA3XTpoh433pm/TXn3pymxjZlzPsig0hnpkcCO3jUibCB5JcpGHPPLxl6fnACPH2DM9Niwees58YH4ZB/gByvMRMnqDVggxlGw/jJgvTyEML6/cXpgyz/Z4udQSZmeBQxEUPQvozJI+190b5ZHfZQJ45HORx+gep4BzOfJPOI/AJRExZATuHvsG7EtCufKYWB6Fli2PifcdKVeP4VviftRMCCFEuCjQCyFEhZOUQP9MQsqVx/jyR1VuVB6Fli2P8eePqlx55CERD2OFEEJER1J69EIIISIi9kBvZmvN7JCZtZrZltHPGHLuNjM7aWbvZ6TNMLNXzezj4HN6kG5m9lRQz3tmtlwe8pCHPCrJIydRTAUqYMpQFXCE9AtoNcC7wKICzl8NLAfez0h7EtgS7G8Bngj21wE7Sb/IvBJ4Sx7ykIc8KsUjbx1jlYliA1YBuzOOtwJbCyxj3rAGOgQ0BftNwKFg/4/Ahhz55CEPecijrD3ybXEP3eRaqGQ8DFkUBRhtURR5yEMe8qgEj5zEHejHvFBJxHXJQx7ykEe5e+Qk7kA/5oVKCqCYRVHkIQ95yKPcPXISd6B/G1hgZteaWQ2wnvTiJeOhmEVR5CEPecij3D1yU8gDgyg20k+RD5N+av2LAs99nvTC472kr3QbgZnAHuDj4HNGkNeA3wf1HARWyEMe8pBHJXnk2vRmrBBCVDhxD90IIYSIGAV6IYSocBTohRCiwlGgF0KICkeBXgghKhwFeiGEqHAU6IUQosJRoBdCiArn/2lzrSYv6ohMAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax","execution_count":525,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'ax' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-525-b00e77935981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'ax' is not defined"]}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}